{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3 as ENB3\n",
    "from torchvision.models import efficientnet_v2_s as ENV2S\n",
    "from torchvision.models import regnet_y_128gf as RNY128\n",
    "from torchvision.models import regnet_y_16gf as RNY16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file_name = 'dataset/embeddings-RNY16.npy'\n",
    "if(os.path.exists(embeddings_file_name) == False):\n",
    "    weights = torchvision.models.RegNet_Y_16GF_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "    using_embedding_model = RNY16(weights=weights)\n",
    "    embedding_size = using_embedding_model.fc.in_features # may change to 'classifier[1]' depending on the model\n",
    "\n",
    "\n",
    "model_file = 'RNY16-similar.pth'\n",
    "result_filename = 'results-RNY16-similar.txt'\n",
    "\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(embeddings_file_name):\n",
    "    \"\"\"\n",
    "    Transform, resize and normalize the images and then use a pretrained model to extract \n",
    "    the embeddings.\n",
    "    \"\"\"\n",
    "    # TODO: define a transform to pre-process the images\n",
    "    # train_transforms = transforms.Compose(\n",
    "    #     # maybe need to resize?\n",
    "    #     # [transforms.Resize((224, 224)),]\n",
    "    #     # maybe normalize?\n",
    "    #     # [transforms.Normalize()]\n",
    "    #     [transforms.ToTensor()])\n",
    "    train_dataset = datasets.ImageFolder(root=\"./dataset/\", transform=weights.transforms())\n",
    "    # Hint: adjust batch_size and num_workers to your PC configuration, so that you don't \n",
    "    # run out of memory\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              pin_memory=True, num_workers=6)\n",
    "\n",
    "    # TODO: define a model for extraction of the embeddings (Hint: load a pretrained model,\n",
    "    #  more info here: https://pytorch.org/vision/stable/models.html)\n",
    "    # model = nn.Module()\n",
    "    model = using_embedding_model\n",
    "    embeddings = []\n",
    "    # embedding_size = model.fc.in_features  # Dummy variable, replace with the actual embedding size once you pick your model\n",
    "\n",
    "    num_images = len(train_dataset)\n",
    "    embeddings = np.zeros((num_images, embedding_size))\n",
    "    # TODO: Use the model to extract the embeddings. Hint: remove the last layers of the \n",
    "    # model to access the embeddings the model generates.\n",
    "\n",
    "    # remove last layer\n",
    "    model = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # extract embeddings\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        embeddings[i] = model(images.to(device)).flatten().cpu().detach().numpy()\n",
    "\n",
    "    np.save(embeddings_file_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embedding for each image in the dataset\n",
    "if(os.path.exists(embeddings_file_name) == False):\n",
    "    generate_embeddings(embeddings_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file, train=True):\n",
    "    \"\"\"\n",
    "    Load the triplets from the file and generate the features and labels.\n",
    "\n",
    "    input: file: string, the path to the file containing the triplets\n",
    "          train: boolean, whether the data is for training or testing\n",
    "\n",
    "    output: X: numpy array, the features\n",
    "            y: numpy array, the labels\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            triplets.append(line)\n",
    "\n",
    "    # generate training data from triplets\n",
    "    train_dataset = datasets.ImageFolder(root=\"dataset/\",\n",
    "                                         transform=None)\n",
    "    filenames = [s[0].split('\\\\')[-1].replace('.jpg', '') for s in train_dataset.samples]\n",
    "    embeddings = np.load(embeddings_file_name)\n",
    "    # TODO: Normalize the embeddings across the dataset\n",
    "    embeddings = StandardScaler().fit_transform(embeddings)\n",
    "\n",
    "    file_to_embedding = {}\n",
    "    for i in range(len(filenames)):\n",
    "        file_to_embedding[filenames[i]] = embeddings[i]\n",
    "    X = []\n",
    "    # use the individual embeddings to generate the features and labels for triplets\n",
    "    for t in triplets:\n",
    "        emb = [file_to_embedding[a] for a in t.split()]\n",
    "        X.append(np.vstack([emb[0], emb[1], emb[2]]))\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory\n",
    "def create_loader_from_np(X, y = None, train = True, batch_size=64, shuffle=True, num_workers = 4):\n",
    "    \"\"\"\n",
    "    Create a torch.utils.data.DataLoader object from numpy arrays containing the data.\n",
    "\n",
    "    input: X: numpy array, the features\n",
    "           y: numpy array, the labels\n",
    "    \n",
    "    output: loader: torch.data.util.DataLoader, the object containing the data\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
    "    loader = DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle,\n",
    "                        pin_memory=True, num_workers=num_workers)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define a model. Here, the basic structure is defined, but you need to fill in the details\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    The model class, which defines our classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_size):\n",
    "        \"\"\"\n",
    "        The constructor of the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = 1024\n",
    "        self.fc1 = nn.Linear(embedding_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, A, B):\n",
    "        output1 = self.forward_once(A)\n",
    "        output2 = self.forward_once(B)\n",
    "        distance = torch.abs(output1 - output2)\n",
    "        distance = self.fc3(distance)\n",
    "        x = F.sigmoid(distance)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader):\n",
    "    \"\"\"\n",
    "    The training procedure of the model; it accepts the training data, defines the model \n",
    "    and then trains it.\n",
    "\n",
    "    input: train_loader: torch.data.util.DataLoader, the object containing the training data\n",
    "    \n",
    "    output: model: torch.nn.Module, the trained model\n",
    "    \"\"\"\n",
    "    embedding_size = train_loader.dataset.tensors[0].shape[-1]\n",
    "    model = Net(embedding_size)\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    # TODO: define a loss function, optimizer and proceed with training. Hint: use the part \n",
    "    # of the training data as a validation split. After each epoch, compute the loss on the \n",
    "    # validation split and print it out. This enables you to see how your model is performing \n",
    "    # on the validation data before submitting the results on the server. After choosing the \n",
    "    # best model, train it on the whole training data.\n",
    "    loss_fun = nn.BCELoss()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.3, patience=3, verbose=True)\n",
    "    train_size = len(train_loader.dataset)\n",
    "    valid_size = int(train_size * 0.1)\n",
    "    train_size = train_size - valid_size\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(train_loader.dataset, [train_size, valid_size])\n",
    "    epoch_train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    epoch_valid_loader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        number_of_correct_train = 0\n",
    "        number_of_correct_valid = 0\n",
    "        for [x] in epoch_train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            A, B, C = x[:, 0, :].to(device), x[:, 1, :].to(device), x[:, 2, :].to(device)\n",
    "            similarity1 = model(A, B).flatten()\n",
    "            similarity2 = model(A, C).flatten()\n",
    "            loss = loss_fun(similarity1, 1) + loss_fun(similarity2, 0)\n",
    "            train_loss += loss.item()\n",
    "            number_of_correct_train += torch.sum(similarity1 > similarity2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss /= len(epoch_train_loader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for [x] in epoch_valid_loader:\n",
    "                A, B, C = x[:, 0, :].to(device), x[:, 1, :].to(device), x[:, 2, :].to(device)\n",
    "                similarity1 = model(A, B).flatten()\n",
    "                similarity2 = model(A, C).flatten()\n",
    "                loss = loss_fun(similarity1, 1) + loss_fun(similarity2, 0)\n",
    "                number_of_correct_valid += torch.sum(similarity1 > similarity2)\n",
    "                valid_loss += loss.item()\n",
    "            valid_loss /= len(epoch_valid_loader)\n",
    "\n",
    "        scheduler.step(number_of_correct_valid / valid_size)\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch+1, train_loss, valid_loss))\n",
    "        print('Training Accuracy: {:.4f}, Validation Accuracy: {:.4f}'.format(number_of_correct_train / train_size, number_of_correct_valid / valid_size))\n",
    "        if (optimizer.param_groups[0]['lr'] < 1e-6):\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, filename='results.txt'):\n",
    "    \"\"\"\n",
    "    The testing procedure of the model; it accepts the testing data and the trained model and \n",
    "    then tests the model on it.\n",
    "\n",
    "    input: model: torch.nn.Module, the trained model\n",
    "           loader: torch.data.util.DataLoader, the object containing the testing data\n",
    "        \n",
    "    output: None, the function saves the predictions to a results.txt file\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    # Iterate over the test data\n",
    "    with torch.no_grad(): # We don't need to compute gradients for testing\n",
    "        for [x_batch] in tqdm(loader):\n",
    "            A, B, C = x_batch[:, 0, :].to(device), x_batch[:, 1, :].to(device), x_batch[:, 2, :].to(device)\n",
    "            similarity1 = model(A, B).flatten()\n",
    "            similarity2 = model(A, C).flatten()\n",
    "            predictions.append(similarity1 > similarity2)\n",
    "        predictions = predictions.cpu().numpy().astype(int)\n",
    "        np.savetxt(filename, predictions, fmt='%i')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_test_model(train=True):\n",
    "    if train:\n",
    "        # define a model and train it\n",
    "        TRAIN_TRIPLETS = 'train_triplets.txt'\n",
    "\n",
    "        # load the training and testing data\n",
    "        X = get_data(TRAIN_TRIPLETS)\n",
    "        print(X.shape)\n",
    "        \n",
    "\n",
    "        # Create data loaders for the training and testing data\n",
    "        train_loader = create_loader_from_np(X, train = True, batch_size=64)\n",
    "        model = train_model(train_loader)\n",
    "        # model = train_without_valid(train_loader)\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "    else:\n",
    "            # test the model on the test data\n",
    "            TEST_TRIPLETS = 'test_triplets.txt'\n",
    "            X_test = get_data(TEST_TRIPLETS, train=False)\n",
    "            test_loader = create_loader_from_np(X_test, train = False, batch_size=2048, shuffle=False)\n",
    "            \n",
    "            # load the model from the file\n",
    "            model = Net(X_test.shape[-1])\n",
    "            model.load_state_dict(torch.load(model_file))\n",
    "            # model.to(device)\n",
    "            \n",
    "            test_model(model, test_loader, None, result_filename)\n",
    "            print(\"Results saved to\", result_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59515, 3, 3024)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68ef47a09ea422b8d8e5ce68ab8e076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_or_test_model(train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtrain_or_test_model\u001b[1;34m(train)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Create data loaders for the training and testing data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m train_loader \u001b[39m=\u001b[39m create_loader_from_np(X, train \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m model \u001b[39m=\u001b[39m train_model(train_loader)\n\u001b[0;32m     14\u001b[0m \u001b[39m# model = train_without_valid(train_loader)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), model_file)\n",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     38\u001b[0m similarity1 \u001b[39m=\u001b[39m model(A, B)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     39\u001b[0m similarity2 \u001b[39m=\u001b[39m model(A, C)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m---> 40\u001b[0m loss \u001b[39m=\u001b[39m loss_fun(similarity1, \u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39m loss_fun(similarity2, \u001b[39m0\u001b[39m)\n\u001b[0;32m     41\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     42\u001b[0m number_of_correct_train \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(similarity1 \u001b[39m>\u001b[39m similarity2)\n",
      "File \u001b[1;32mc:\\Users\\linan\\.conda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\linan\\.conda\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\linan\\.conda\\envs\\DL\\lib\\site-packages\\torch\\nn\\functional.py:3088\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3086\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m-> 3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39;49msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m   3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m   3092\u001b[0m     )\n\u001b[0;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_or_test_model(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedbb7b10c5f4254bc39497511aea01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results-RNY16-conv.txt\n"
     ]
    }
   ],
   "source": [
    "train_or_test_model(train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
